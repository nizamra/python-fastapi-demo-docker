# AI Usage Documentation

## AI Tools Used
- **github Copilot (GPT-4o), Z.ai (https://chat.z.ai/)**

## Prompts and Instructions

I used the AI primarily as a **Code Generator**. Below are the specific prompts and instructions used to generate the project structure and code.

### Example 1: Project Structure and Documentation

**Prompt:**
> "I need to generate a complete folder structure for a project deployed on GCP.
> Create a `docs` folder with files: RELEASE_PROCESS.md, ARCHITECTURE_GCP.md, DEPLOYMENT.md, ROLLBACK.md, GKE_RUNBOOK.md."

**Result:**
- Generated the file tree structure.
- Created basic filler content for `docs/GKE_RUNBOOK.md` and `docs/ROLLBACK.md` (see the respective markdown files in the repo).

### Example 2: Bootstrapping and CI/CD

**Prompt:**
> "Create a folder for `bootstrap` with full Terraform code for creating a GCS state bucket and opening APIs (container, artifact registry, storage).
> 
> Also, generate GitHub Actions YAML for building a docker image and uploading to GCP artifact registry. Use Workload Identity Federation for authentication."

**Result:**
- Created `bootstrap/main.tf`, `bootstrap/apis.tf`, `bootstrap/bucket.tf`.
- Created `.github/workflows/docker-build-gcp.yml` with `google-github-actions/auth@v2` and `gcloud auth configure-docker`.

### Example 3: Infrastructure and Modules

**Prompt:**
> "Generate a folder structure for `infra` with:
> 1. `envs` subfolder: dev, stag and prod, holding files for main, variables, outputs, and values.tfvars.
> 2. `modules` subfolder.
> 3. Include `backend.tf` and `providers.tf` configurations.
> 
> Ensure the Terraform code uses a GCS backend for remote state."

**Result:**
- Created `infra/envs/dev/`, `infra/envs/prod/` directory structures.
- Created `infra/modules/gke-cluster/` and `infra/modules/artifact-registry/`.
- Configured `terraform { backend "gcs" { ... } }` blocks.

### Example 4: Deployment Pipelines

**Prompt:**
> "Generate a pipeline for infrastructure with multiple jobs: one for dev, another for prod. The prod job should only run on main branch and require manual approval.
> 
> Generate a separate pipeline for taking the image from registry and deploying in GKE. It should support retagging images (e.g., from SHA to v1.0.0) and using kubectl to apply manifests."

**Result:**
- Created `.github/workflows/infra-pipeline.yml` with `jobs: deploy-infra-dev` and `deploy-infra-prod` using `needs` and `environment: prod`.
- Created `.github/workflows/cd-deploy.yml` with logic for `gcloud artifacts docker tags add` and `kubectl apply`.

## Parts Influenced by AI

- **Terraform**: 
  - Module files creation (`modules/gke-cluster`, `modules/artifact-registry`).
  - `main.tf` wiring for environments.
  - Backend configuration and provider code.
- **GitHub Actions**: 
  - Complete logic for `.github/workflows/docker-build-gcp.yml` (authentication, tagging).
  - Complete logic for `.github/workflows/cd-deploy.yml` (promotion, manual approval, kubectl patch).
- **Kubernetes**: 
  - Fixing `StatefulSet` configurations for GKE Autopilot.
  - Creating `ConfigMap` strategies for database initialization.
- **Documentation**: 
  - Drafting basic Markdown files in the `docs/` folder.

## Verification

All code generated by AI was reviewed for:
- Syntax errors (Terraform validate, YAML linting).
- Security best practices (avoiding hardcoded secrets, using Workload Identity).
- Compatibility with the specific GCP project constraints (Autopilot, regions).
- the best way to verify is to deploy
